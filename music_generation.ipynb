{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library for understanding music\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: haydn/haydn_33_1.mid\n",
      "Loading Music File: haydn/haydn_33_2.mid\n",
      "Loading Music File: haydn/haydn_33_3.mid\n",
      "Loading Music File: haydn/haydn_35_1.mid\n",
      "Loading Music File: haydn/haydn_35_2.mid\n",
      "Loading Music File: haydn/haydn_35_3.mid\n",
      "Loading Music File: haydn/haydn_43_1.mid\n",
      "Loading Music File: haydn/haydn_43_2.mid\n",
      "Loading Music File: haydn/haydn_43_3.mid\n",
      "Loading Music File: haydn/haydn_7_1.mid\n",
      "Loading Music File: haydn/haydn_7_2.mid\n",
      "Loading Music File: haydn/haydn_7_3.mid\n",
      "Loading Music File: haydn/haydn_8_1.mid\n",
      "Loading Music File: haydn/haydn_8_2.mid\n",
      "Loading Music File: haydn/haydn_8_3.mid\n",
      "Loading Music File: haydn/haydn_8_4.mid\n",
      "Loading Music File: haydn/haydn_9_1.mid\n",
      "Loading Music File: haydn/haydn_9_2.mid\n",
      "Loading Music File: haydn/haydn_9_3.mid\n",
      "Loading Music File: haydn/hay_40_1.mid\n",
      "Loading Music File: haydn/hay_40_2.mid\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='haydn/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([134.,  14.,  12.,   5.,   6.,   2.,   0.,   3.,   2.,   1.]),\n",
       " array([1.0000e+00, 1.4580e+02, 2.9060e+02, 4.3540e+02, 5.8020e+02,\n",
       "        7.2500e+02, 8.6980e+02, 1.0146e+03, 1.1594e+03, 1.3042e+03,\n",
       "        1.4490e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 305,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           7500      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 235,095\n",
      "Trainable params: 235,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/149 [============================>.] - ETA: 0s - loss: 3.8223\n",
      "Epoch 00001: val_loss improved from inf to 3.67335, saving model to best_model.h5\n",
      "149/149 [==============================] - 14s 92ms/step - loss: 3.8210 - val_loss: 3.6734\n",
      "Epoch 2/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 3.5037\n",
      "Epoch 00002: val_loss improved from 3.67335 to 3.50679, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 3.5037 - val_loss: 3.5068\n",
      "Epoch 3/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 3.3507\n",
      "Epoch 00003: val_loss improved from 3.50679 to 3.38669, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 3.3507 - val_loss: 3.3867\n",
      "Epoch 4/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 3.2467\n",
      "Epoch 00004: val_loss improved from 3.38669 to 3.29945, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 3.2467 - val_loss: 3.2994\n",
      "Epoch 5/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 3.1562\n",
      "Epoch 00005: val_loss improved from 3.29945 to 3.22148, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 3.1562 - val_loss: 3.2215\n",
      "Epoch 6/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 3.0836\n",
      "Epoch 00006: val_loss improved from 3.22148 to 3.20022, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 3.0836 - val_loss: 3.2002\n",
      "Epoch 7/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 3.0170\n",
      "Epoch 00007: val_loss improved from 3.20022 to 3.08162, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 3.0170 - val_loss: 3.0816\n",
      "Epoch 8/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.9548\n",
      "Epoch 00008: val_loss improved from 3.08162 to 3.07483, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 2.9548 - val_loss: 3.0748\n",
      "Epoch 9/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.8923\n",
      "Epoch 00009: val_loss improved from 3.07483 to 3.03978, saving model to best_model.h5\n",
      "149/149 [==============================] - 14s 95ms/step - loss: 2.8923 - val_loss: 3.0398\n",
      "Epoch 10/50\n",
      "148/149 [============================>.] - ETA: 0s - loss: 2.8365\n",
      "Epoch 00010: val_loss improved from 3.03978 to 2.99067, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 2.8362 - val_loss: 2.9907\n",
      "Epoch 11/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.7908\n",
      "Epoch 00011: val_loss improved from 2.99067 to 2.95334, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 2.7908 - val_loss: 2.9533\n",
      "Epoch 12/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.7437\n",
      "Epoch 00012: val_loss improved from 2.95334 to 2.90255, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 2.7437 - val_loss: 2.9025\n",
      "Epoch 13/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.6989\n",
      "Epoch 00013: val_loss improved from 2.90255 to 2.88163, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 2.6989 - val_loss: 2.8816\n",
      "Epoch 14/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.6411\n",
      "Epoch 00014: val_loss improved from 2.88163 to 2.85433, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 2.6411 - val_loss: 2.8543\n",
      "Epoch 15/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.6034\n",
      "Epoch 00015: val_loss improved from 2.85433 to 2.81752, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 2.6034 - val_loss: 2.8175\n",
      "Epoch 16/50\n",
      "148/149 [============================>.] - ETA: 0s - loss: 2.5553\n",
      "Epoch 00016: val_loss improved from 2.81752 to 2.80566, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 2.5549 - val_loss: 2.8057\n",
      "Epoch 17/50\n",
      "148/149 [============================>.] - ETA: 0s - loss: 2.5134\n",
      "Epoch 00017: val_loss improved from 2.80566 to 2.76383, saving model to best_model.h5\n",
      "149/149 [==============================] - 10s 68ms/step - loss: 2.5131 - val_loss: 2.7638\n",
      "Epoch 18/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.4766\n",
      "Epoch 00018: val_loss improved from 2.76383 to 2.74428, saving model to best_model.h5\n",
      "149/149 [==============================] - 10s 65ms/step - loss: 2.4766 - val_loss: 2.7443\n",
      "Epoch 19/50\n",
      "148/149 [============================>.] - ETA: 0s - loss: 2.4367\n",
      "Epoch 00019: val_loss improved from 2.74428 to 2.68963, saving model to best_model.h5\n",
      "149/149 [==============================] - 10s 66ms/step - loss: 2.4361 - val_loss: 2.6896\n",
      "Epoch 20/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.4146\n",
      "Epoch 00020: val_loss improved from 2.68963 to 2.67870, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 2.4146 - val_loss: 2.6787\n",
      "Epoch 21/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.3691\n",
      "Epoch 00021: val_loss did not improve from 2.67870\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 2.3691 - val_loss: 2.6795\n",
      "Epoch 22/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.3287\n",
      "Epoch 00022: val_loss improved from 2.67870 to 2.65222, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 2.3287 - val_loss: 2.6522\n",
      "Epoch 23/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.2965\n",
      "Epoch 00023: val_loss improved from 2.65222 to 2.62264, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 2.2965 - val_loss: 2.6226\n",
      "Epoch 24/50\n",
      "148/149 [============================>.] - ETA: 0s - loss: 2.2825\n",
      "Epoch 00024: val_loss improved from 2.62264 to 2.59301, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 2.2825 - val_loss: 2.5930\n",
      "Epoch 25/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.2470\n",
      "Epoch 00025: val_loss did not improve from 2.59301\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 2.2470 - val_loss: 2.6165\n",
      "Epoch 26/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.2063\n",
      "Epoch 00026: val_loss did not improve from 2.59301\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 2.2063 - val_loss: 2.5983\n",
      "Epoch 27/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.1801\n",
      "Epoch 00027: val_loss improved from 2.59301 to 2.53965, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 2.1801 - val_loss: 2.5396\n",
      "Epoch 28/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.1635\n",
      "Epoch 00028: val_loss improved from 2.53965 to 2.51465, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 2.1635 - val_loss: 2.5147\n",
      "Epoch 29/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.1323\n",
      "Epoch 00029: val_loss improved from 2.51465 to 2.50354, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 88ms/step - loss: 2.1323 - val_loss: 2.5035\n",
      "Epoch 30/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.1056\n",
      "Epoch 00030: val_loss improved from 2.50354 to 2.49420, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 2.1056 - val_loss: 2.4942\n",
      "Epoch 31/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.0908\n",
      "Epoch 00031: val_loss improved from 2.49420 to 2.47391, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 2.0908 - val_loss: 2.4739\n",
      "Epoch 32/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.0574\n",
      "Epoch 00032: val_loss improved from 2.47391 to 2.45403, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 2.0574 - val_loss: 2.4540\n",
      "Epoch 33/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.0336\n",
      "Epoch 00033: val_loss improved from 2.45403 to 2.44919, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 2.0336 - val_loss: 2.4492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.0027\n",
      "Epoch 00034: val_loss improved from 2.44919 to 2.41507, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 2.0027 - val_loss: 2.4151\n",
      "Epoch 35/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.9869\n",
      "Epoch 00035: val_loss did not improve from 2.41507\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 1.9869 - val_loss: 2.4169\n",
      "Epoch 36/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.9642\n",
      "Epoch 00036: val_loss improved from 2.41507 to 2.39294, saving model to best_model.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 1.9642 - val_loss: 2.3929\n",
      "Epoch 37/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.9673\n",
      "Epoch 00037: val_loss improved from 2.39294 to 2.37471, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 1.9673 - val_loss: 2.3747\n",
      "Epoch 38/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.9347\n",
      "Epoch 00038: val_loss improved from 2.37471 to 2.35925, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 1.9347 - val_loss: 2.3593\n",
      "Epoch 39/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.9303\n",
      "Epoch 00039: val_loss did not improve from 2.35925\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 1.9303 - val_loss: 2.3674\n",
      "Epoch 40/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8941\n",
      "Epoch 00040: val_loss improved from 2.35925 to 2.33139, saving model to best_model.h5\n",
      "149/149 [==============================] - 11s 76ms/step - loss: 1.8941 - val_loss: 2.3314\n",
      "Epoch 41/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8947\n",
      "Epoch 00041: val_loss improved from 2.33139 to 2.32943, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 1.8947 - val_loss: 2.3294\n",
      "Epoch 42/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8738\n",
      "Epoch 00042: val_loss improved from 2.32943 to 2.32087, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 1.8738 - val_loss: 2.3209\n",
      "Epoch 43/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8438\n",
      "Epoch 00043: val_loss improved from 2.32087 to 2.29142, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 78ms/step - loss: 1.8438 - val_loss: 2.2914\n",
      "Epoch 44/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8262\n",
      "Epoch 00044: val_loss did not improve from 2.29142\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 1.8262 - val_loss: 2.3008\n",
      "Epoch 45/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8294\n",
      "Epoch 00045: val_loss improved from 2.29142 to 2.28317, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 80ms/step - loss: 1.8294 - val_loss: 2.2832\n",
      "Epoch 46/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8056\n",
      "Epoch 00046: val_loss improved from 2.28317 to 2.26918, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 1.8056 - val_loss: 2.2692\n",
      "Epoch 47/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.793 - ETA: 0s - loss: 1.7937\n",
      "Epoch 00047: val_loss improved from 2.26918 to 2.25155, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 1.7937 - val_loss: 2.2516\n",
      "Epoch 48/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.7793\n",
      "Epoch 00048: val_loss improved from 2.25155 to 2.25129, saving model to best_model.h5\n",
      "149/149 [==============================] - 12s 79ms/step - loss: 1.7793 - val_loss: 2.2513\n",
      "Epoch 49/50\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.7765\n",
      "Epoch 00049: val_loss did not improve from 2.25129\n",
      "149/149 [==============================] - 11s 77ms/step - loss: 1.7765 - val_loss: 2.2588\n",
      "Epoch 50/50\n",
      "148/149 [============================>.] - ETA: 0s - loss: 1.7556\n",
      "Epoch 00050: val_loss improved from 2.25129 to 2.21536, saving model to best_model.h5\n",
      "149/149 [==============================] - 10s 69ms/step - loss: 1.7567 - val_loss: 2.2154\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 74, 74, 74, 40, 21, 74, 25, 46, 63]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
